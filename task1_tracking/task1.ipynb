{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ME5413: Autonomous Mobile Robot  \n",
    "\n",
    "### Homework 1: Perception  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Install Packages\n",
    "Prefered use of these version so that the code can be run during evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy==1.23\n",
    "# !pip install torch==2.1.0\n",
    "# !pip install transformers==4.48.1\n",
    "# !pip install timm==1.0.14\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, DetrForObjectDetection\n",
    "from PIL import Image, ImageDraw\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "from yolov5 import YOLOv5\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1 Single-Object Tracking \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## put your code here\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Template Matching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.1.1 Different Template Matching methods for different sequences\n",
    "This script performs Template Matching (TM) on 5 sequences using 6 different matching methods.\n",
    "The results for each method and sequence are saved in separate text files for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_matching(input_dir, firsttrack_filename, output_dir):\n",
    "    img_folder = os.path.join(input_dir, \"img/\")\n",
    "    first_image_path = os.path.join(img_folder, \"00000001.jpg\")\n",
    "    firsttrack_path = os.path.join(input_dir, firsttrack_filename)\n",
    "\n",
    "    # Read initial bounding box\n",
    "    with open(firsttrack_path, \"r\") as f:\n",
    "        bbox = list(map(int, f.readline().strip().split(\",\")))\n",
    "\n",
    "    # Read the first image and extract the template\n",
    "    first_image = cv2.imread(first_image_path)\n",
    "    template = first_image[bbox[1] : bbox[1] + bbox[3], bbox[0] : bbox[0] + bbox[2]]\n",
    "\n",
    "    # Define different template matching methods\n",
    "    methods = {\n",
    "        \"TM_CCOEFF\": cv2.TM_CCOEFF,\n",
    "        \"TM_CCOEFF_NORMED\": cv2.TM_CCOEFF_NORMED,\n",
    "        \"TM_CCORR\": cv2.TM_CCORR,\n",
    "        \"TM_CCORR_NORMED\": cv2.TM_CCORR_NORMED,\n",
    "        \"TM_SQDIFF\": cv2.TM_SQDIFF,\n",
    "        \"TM_SQDIFF_NORMED\": cv2.TM_SQDIFF_NORMED,\n",
    "    }\n",
    "\n",
    "    image_files = sorted(f for f in os.listdir(img_folder) if f.endswith(\".jpg\"))\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for method_name, method in methods.items():\n",
    "        method_output_file = os.path.join(output_dir, f\"trackresults_{method_name}.txt\")\n",
    "        result_lines = []\n",
    "\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(img_folder, img_file)\n",
    "            frame = cv2.imread(img_path)\n",
    "\n",
    "            # Apply template matching\n",
    "            res = cv2.matchTemplate(frame, template, method)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "            # Determine bounding box based on the method\n",
    "            if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "                top_left = (\n",
    "                    min_loc  # For these methods, the best match has the lowest value\n",
    "                )\n",
    "            else:\n",
    "                top_left = max_loc\n",
    "\n",
    "            x, y, w, h = top_left[0], top_left[1], template.shape[1], template.shape[0]\n",
    "            result_lines.append(f\"{x},{y},{w},{h}\")\n",
    "\n",
    "        # Save results for each method\n",
    "        with open(method_output_file, \"w\") as f:\n",
    "            f.write(\"\\n\".join(result_lines))\n",
    "\n",
    "        print(f\"Results saved to: {method_output_file}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_input_directory = \"data/\"\n",
    "    firsttrack_filename = \"firsttrack.txt\"\n",
    "    output_base_directory = \"results/1_template_matching/\"\n",
    "\n",
    "    seq_list = [1, 2, 3, 4, 5]\n",
    "    for seq_num in seq_list:\n",
    "        input_directory = os.path.join(base_input_directory, f\"seq{seq_num}\")\n",
    "        output_directory = os.path.join(output_base_directory, f\"seq{seq_num}\")\n",
    "\n",
    "        template_matching(input_directory, firsttrack_filename, output_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.1.2 Template Matching and Adaptive Template Update\n",
    "\n",
    "This script implements a single-object tracker using TM with Adaptive Template Updating (ATU). TM is used to locate the object in each frame, while ATU updates the template dynamically based on a confidence threshold to adapt to appearance changes, improving tracking robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleObjectTracker:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dir,\n",
    "        firsttrack_filename,\n",
    "        output_filename,\n",
    "        matching_method,\n",
    "        alpha=0.1,\n",
    "        confidence_threshold=0.6,\n",
    "    ):\n",
    "        self.img_folder = os.path.join(input_dir, \"img/\")\n",
    "        self.first_image_path = os.path.join(self.img_folder, \"00000001.jpg\")\n",
    "        self.firsttrack_path = os.path.join(input_dir, firsttrack_filename)\n",
    "        self.output_filename = output_filename\n",
    "        self.alpha = alpha\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.matching_method = matching_method\n",
    "\n",
    "        # Read initial bounding box\n",
    "        self.template, self.bbox = self._initialize_template()\n",
    "\n",
    "    def _initialize_template(self):\n",
    "        # Read the first bounding box from file\n",
    "        with open(self.firsttrack_path, \"r\") as f:\n",
    "            bbox = list(\n",
    "                map(int, f.readline().strip().split(\",\"))\n",
    "            )  # [x, y, width, height]\n",
    "\n",
    "        # Load the first image and extract the template\n",
    "        first_image = cv2.imread(self.first_image_path)\n",
    "        template = first_image[bbox[1] : bbox[1] + bbox[3], bbox[0] : bbox[0] + bbox[2]]\n",
    "        return template, bbox\n",
    "\n",
    "    def _update_template(self, current_frame, bbox, score):\n",
    "        if score > self.confidence_threshold:\n",
    "            x, y, w, h = bbox\n",
    "            new_template = current_frame[y : y + h, x : x + w]\n",
    "            if new_template.shape == self.template.shape:\n",
    "                self.template = cv2.addWeighted(\n",
    "                    self.template, 1 - self.alpha, new_template, self.alpha, 0\n",
    "                )\n",
    "\n",
    "    def track(self):\n",
    "        result_lines = []\n",
    "        image_files = sorted(\n",
    "            [f for f in os.listdir(self.img_folder) if f.endswith(\".jpg\")]\n",
    "        )\n",
    "\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(self.img_folder, img_file)\n",
    "            frame = cv2.imread(img_path)\n",
    "\n",
    "            # Template matching using the selected method\n",
    "            res = cv2.matchTemplate(frame, self.template, self.matching_method)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "            if self.matching_method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "                top_left = min_loc  # For SQDIFF methods, lower values are better\n",
    "                score = 1.0 - min_val  # Normalize to be confidence-like\n",
    "            else:\n",
    "                top_left = max_loc  # For other methods, higher values are better\n",
    "                score = max_val  # Direct use of max_val as score\n",
    "\n",
    "            # Calculate bounding box for the matched region\n",
    "            h, w = self.template.shape[:2]\n",
    "            bbox = (top_left[0], top_left[1], w, h)\n",
    "\n",
    "            # Update template if confidence is high\n",
    "            self._update_template(frame, bbox, score)\n",
    "\n",
    "            # Logging the processed frame\n",
    "            result_lines.append(f\"{bbox[0]},{bbox[1]},{bbox[2]},{bbox[3]}\")\n",
    "\n",
    "        # Save tracking results\n",
    "        os.makedirs(os.path.dirname(self.output_filename), exist_ok=True)\n",
    "        with open(self.output_filename, \"w\") as f:\n",
    "            f.write(\"\\n\".join(result_lines))\n",
    "\n",
    "        print(f\"Results saved to: {self.output_filename}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_input_directory = \"data/\"\n",
    "    firsttrack_filename = \"firsttrack.txt\"\n",
    "    output_directory = \"results/1_template_matching/\"\n",
    "\n",
    "    seq_matching_methods = {\n",
    "        1: cv2.TM_CCOEFF,\n",
    "        2: cv2.TM_CCOEFF,\n",
    "        3: cv2.TM_CCOEFF_NORMED,\n",
    "        4: cv2.TM_SQDIFF_NORMED,\n",
    "        5: cv2.TM_CCOEFF_NORMED,\n",
    "    }\n",
    "\n",
    "    seq_list = [1, 2, 3, 4, 5]\n",
    "    for seq_num in seq_list:\n",
    "        input_directory = os.path.join(base_input_directory, f\"seq{seq_num}\")\n",
    "        output_filename = os.path.join(\n",
    "            output_directory, f\"trackresults_TM_ATU_seq{seq_num}.txt\"\n",
    "        )\n",
    "\n",
    "        matching_method = seq_matching_methods[seq_num]\n",
    "\n",
    "        tracker = SingleObjectTracker(\n",
    "            input_directory,\n",
    "            firsttrack_filename,\n",
    "            output_filename,\n",
    "            matching_method,\n",
    "            alpha=0.05,\n",
    "        )\n",
    "        tracker.track()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.1.3 Template matching, Adaptive Template Update, and Kalman Filter\n",
    "\n",
    "The script implements the modification by using a Kalman filter (KF) to smooth the tracking results, thus reducing noise and improving robustness across sequential images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter:\n",
    "    def __init__(self, init_bbox):\n",
    "        self.kf = cv2.KalmanFilter(\n",
    "            4, 2\n",
    "        )  # State variables (x, y, dx, dy), measurement variables (x, y)\n",
    "        self.kf.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "        self.kf.transitionMatrix = np.array(\n",
    "            [[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32\n",
    "        )\n",
    "        self.kf.processNoiseCov = np.eye(4, dtype=np.float32) * 1e-2\n",
    "        self.kf.measurementNoiseCov = np.eye(2, dtype=np.float32) * 1e-1\n",
    "        self.kf.errorCovPost = np.eye(4, dtype=np.float32) * 0.1\n",
    "        self.kf.statePost = np.array([init_bbox[0], init_bbox[1], 0, 0], np.float32)\n",
    "\n",
    "    def predict(self):\n",
    "        pred = self.kf.predict()\n",
    "        return int(pred[0]), int(pred[1])\n",
    "\n",
    "    def correct(self, measured_x, measured_y):\n",
    "        measurement = np.array([[np.float32(measured_x)], [np.float32(measured_y)]])\n",
    "        corrected = self.kf.correct(measurement)\n",
    "        return int(corrected[0]), int(corrected[1])\n",
    "\n",
    "\n",
    "class SingleObjectTracker:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dir,\n",
    "        firsttrack_filename,\n",
    "        output_filename,\n",
    "        matching_method,\n",
    "        alpha=0.1,\n",
    "        confidence_threshold=0.6,\n",
    "    ):\n",
    "        self.img_folder = os.path.join(input_dir, \"img/\")\n",
    "        self.first_image_path = os.path.join(self.img_folder, \"00000001.jpg\")\n",
    "        self.firsttrack_path = os.path.join(input_dir, firsttrack_filename)\n",
    "        self.output_filename = output_filename\n",
    "        self.alpha = alpha\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.matching_method = matching_method\n",
    "\n",
    "        # Read the initial bounding box\n",
    "        self.template, self.bbox = self._initialize_template()\n",
    "        self.kalman_filter = KalmanFilter(self.bbox)  # Initialize the Kalman filter\n",
    "\n",
    "    def _initialize_template(self):\n",
    "        with open(self.firsttrack_path, \"r\") as f:\n",
    "            bbox = list(\n",
    "                map(int, f.readline().strip().split(\",\"))\n",
    "            )  # [x, y, width, height]\n",
    "        first_image = cv2.imread(self.first_image_path)\n",
    "        template = first_image[bbox[1] : bbox[1] + bbox[3], bbox[0] : bbox[0] + bbox[2]]\n",
    "        return template, bbox\n",
    "\n",
    "    def _update_template(self, current_frame, bbox, score):\n",
    "        if score > self.confidence_threshold:\n",
    "            x, y, w, h = bbox\n",
    "            new_template = current_frame[y : y + h, x : x + w]\n",
    "            if new_template.shape == self.template.shape:\n",
    "                self.template = cv2.addWeighted(\n",
    "                    self.template, 1 - self.alpha, new_template, self.alpha, 0\n",
    "                )\n",
    "\n",
    "    def track(self):\n",
    "        result_lines = []\n",
    "        image_files = sorted(\n",
    "            [f for f in os.listdir(self.img_folder) if f.endswith(\".jpg\")]\n",
    "        )\n",
    "\n",
    "        for img_file in image_files:\n",
    "            img_path = os.path.join(self.img_folder, img_file)\n",
    "            frame = cv2.imread(img_path)\n",
    "\n",
    "            # Template matching\n",
    "            res = cv2.matchTemplate(frame, self.template, self.matching_method)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "            if self.matching_method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "                top_left = min_loc\n",
    "                score = 1.0 - min_val  # Normalized score\n",
    "            else:\n",
    "                top_left = max_loc\n",
    "                score = max_val\n",
    "\n",
    "            # Compute bounding box\n",
    "            h, w = self.template.shape[:2]\n",
    "            measured_bbox = (top_left[0], top_left[1], w, h)\n",
    "\n",
    "            # Kalman filter correction\n",
    "            pred_x, pred_y = self.kalman_filter.predict()\n",
    "            corrected_x, corrected_y = self.kalman_filter.correct(\n",
    "                measured_bbox[0], measured_bbox[1]\n",
    "            )\n",
    "            smoothed_bbox = (corrected_x, corrected_y, w, h)\n",
    "\n",
    "            # Update template\n",
    "            self._update_template(frame, smoothed_bbox, score)\n",
    "\n",
    "            # Record results\n",
    "            result_lines.append(\n",
    "                f\"{smoothed_bbox[0]},{smoothed_bbox[1]},{smoothed_bbox[2]},{smoothed_bbox[3]}\"\n",
    "            )\n",
    "\n",
    "        # Save tracking results\n",
    "        os.makedirs(os.path.dirname(self.output_filename), exist_ok=True)\n",
    "        with open(self.output_filename, \"w\") as f:\n",
    "            f.write(\"\\n\".join(result_lines))\n",
    "\n",
    "        print(f\"Results saved to: {self.output_filename}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_input_directory = \"data/\"\n",
    "    firsttrack_filename = \"firsttrack.txt\"\n",
    "    output_directory = \"results/1_template_matching/\"\n",
    "\n",
    "    seq_matching_methods = {\n",
    "        1: cv2.TM_CCOEFF,\n",
    "        2: cv2.TM_CCOEFF,\n",
    "        3: cv2.TM_CCOEFF_NORMED,\n",
    "        4: cv2.TM_SQDIFF_NORMED,\n",
    "        5: cv2.TM_CCOEFF_NORMED,\n",
    "    }\n",
    "\n",
    "    seq_list = [1, 2, 3, 4, 5]\n",
    "    for seq_num in seq_list:\n",
    "        input_directory = os.path.join(base_input_directory, f\"seq{seq_num}\")\n",
    "        output_filename = os.path.join(\n",
    "            output_directory, f\"trackresults_TM_ATU_KF_seq{seq_num}.txt\"\n",
    "        )\n",
    "        matching_method = seq_matching_methods[seq_num]\n",
    "\n",
    "        tracker = SingleObjectTracker(\n",
    "            input_directory,\n",
    "            firsttrack_filename,\n",
    "            output_filename,\n",
    "            matching_method,\n",
    "            alpha=0.05,\n",
    "        )\n",
    "        tracker.track()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Object Detection algorithm and Association\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.1.4 End-to-End Object Detection with Transformers\n",
    "\n",
    "This script processes multiple image sequences, performs object detection using a pretrained End-to-End Object Detection with Transformers (DETR) model, tracks the detected objects across frames, and saves the tracking results in text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetectionTracker:\n",
    "    def __init__(self, base_input_directory, base_output_directory, seq_list):\n",
    "        # Initialize with the base directories and sequence list\n",
    "        self.base_input_directory = base_input_directory\n",
    "        self.base_output_directory = base_output_directory\n",
    "        self.seq_list = seq_list\n",
    "\n",
    "        # Load image processor and model\n",
    "        self.image_processor = AutoImageProcessor.from_pretrained(\"./detr-resnet-50\")\n",
    "        self.model = DetrForObjectDetection.from_pretrained(\"./detr-resnet-50\")\n",
    "\n",
    "    def process_seq(self, seq_num):\n",
    "        # Process each sequence individually\n",
    "        seq_dir = os.path.join(self.base_input_directory, f\"seq{seq_num}\")\n",
    "        image_dir = os.path.join(seq_dir, \"img\")\n",
    "        image_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.jpg')])\n",
    "\n",
    "        # Read the first frame's ground truth position\n",
    "        firsttrack_dir = os.path.join(seq_dir, \"firsttrack.txt\")\n",
    "        with open(firsttrack_dir, \"r\") as f:\n",
    "            first_frame_gt = list(map(int, f.read().strip().split(',')))\n",
    "\n",
    "        # Initialize target positions list\n",
    "        target_positions = [first_frame_gt]\n",
    "        result_lines = []\n",
    "\n",
    "        # Create result directory\n",
    "        os.makedirs(self.base_output_directory, exist_ok=True)\n",
    "\n",
    "        # Process each image\n",
    "        for frame_idx, image_file in enumerate(image_files):\n",
    "            # Load image\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "            # Preprocess image\n",
    "            inputs = self.image_processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "            # Run inference\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "            # Get prediction results\n",
    "            target_sizes = torch.tensor([image.size[::-1]])  # (height, width)\n",
    "            results = self.image_processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.75)[0]\n",
    "\n",
    "            # Get all detection boxes for the current frame\n",
    "            boxes = results[\"boxes\"]\n",
    "            labels = results[\"labels\"]\n",
    "            scores = results[\"scores\"]\n",
    "\n",
    "            # Calculate distance to previous target\n",
    "            prev_position = target_positions[-1]\n",
    "            prev_x, prev_y, prev_w, prev_h = prev_position\n",
    "            prev_center = (prev_x + prev_w / 2, prev_y + prev_h / 2)\n",
    "\n",
    "            min_distance = float('inf')\n",
    "            selected_box = None\n",
    "\n",
    "            for box, label in zip(boxes, labels):\n",
    "                min_x, min_y, max_x, max_y = box.tolist()\n",
    "                center = ((max_x + min_x) / 2, (max_y + min_y) / 2)\n",
    "                distance = ((center[0] - prev_center[0]) ** 2 + (center[1] - prev_center[1]) ** 2) ** 0.5\n",
    "\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    selected_box = box\n",
    "\n",
    "            if min_distance > 50:\n",
    "                selected_box = None\n",
    "\n",
    "            # Update target position if a match is found\n",
    "            if selected_box is not None:\n",
    "                min_slct_x, min_slct_y, max_slct_x, max_slct_y = selected_box.tolist()\n",
    "                target_positions.append([min_slct_x, min_slct_y, (max_slct_x - min_slct_x), (max_slct_y - min_slct_y)])\n",
    "            else:\n",
    "                target_positions.append([prev_x, prev_y, prev_w, prev_h])\n",
    "\n",
    "            if selected_box is not None:\n",
    "                result_lines.append(f\"{int(min_slct_x)},{int(min_slct_y)},{int(max_slct_x - min_slct_x)},{int(max_slct_y - min_slct_y)}\")\n",
    "            else:\n",
    "                result_lines.append(f\"{int(prev_x)},{int(prev_y)},{int(prev_w)},{int(prev_h)}\")\n",
    "\n",
    "            # Save the result for the current frame\n",
    "            result_file = os.path.join(self.base_output_directory, f\"trackresults_ODA_seq{seq_num}.txt\")\n",
    "            with open(result_file, \"w\") as f:\n",
    "                f.write(\"\\n\".join(result_lines))\n",
    "\n",
    "    def process_all_seqs(self):\n",
    "        # Loop through all sequences and process them\n",
    "        for seq_num in self.seq_list:\n",
    "            self.process_seq(seq_num)\n",
    "            print(f\"Results of {seq_num} are saved\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # List of sequences to process\n",
    "    seq_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "    # Define base input and output directories\n",
    "    base_input_directory = \"data\"\n",
    "    base_output_directory = \"results/2_objectdetection_withassociation\"\n",
    "\n",
    "    # Create the ObjectDetectionTracker object\n",
    "    tracker = ObjectDetectionTracker(base_input_directory, base_output_directory, seq_list)\n",
    "\n",
    "    # Process all sequences\n",
    "    tracker.process_all_seqs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement\n",
    "\n",
    "#### Task 1.1.5 YOLO5 + Deep SORT\n",
    "\n",
    "Propose Improvements to the work if possible:\n",
    "\n",
    "This script uses YOLOv5 for object detection and DeepSORT for object tracking to process multiple image sequences, track detected objects, and save the tracking results to text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## put your code here: This function should be able to visualise this image and their tracking results\n",
    "img_file = 'data/Task 1/seq2/img/00000002.jpg'\n",
    "\n",
    "print('Tracking Results for this image using Improved Method is (in xmin, ymin, width, height): ???') \n",
    "## show image of visualised result of ground truth and track results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectTracking:\n",
    "    def __init__(self, yolo_model_path, deepsort_model_path, base_input_directory, output_directory, seq_list, firsttrack_filename):\n",
    "        # Initialize YOLOv5 and DeepSORT models\n",
    "        self.yolo_model = YOLOv5(yolo_model_path)\n",
    "        self.deepsort_model = DeepSort(deepsort_model_path)\n",
    "        self.deepsort = DeepSort(max_age=30, n_init=3)\n",
    "        \n",
    "        self.base_input_directory = base_input_directory\n",
    "        self.output_directory = output_directory\n",
    "        self.seq_list = seq_list\n",
    "        self.firsttrack_filename = firsttrack_filename\n",
    "    \n",
    "    def load_firsttrack(self, seq_num):\n",
    "        with open(self.base_input_directory + f\"seq{seq_num}/\" + self.firsttrack_filename, 'r') as f:\n",
    "            firsttrack = [list(map(int, line.strip().split(','))) for line in f.readlines()]\n",
    "        return firsttrack\n",
    "    \n",
    "    def calculate_distance(self, bbox1, bbox2):\n",
    "        center1 = ((bbox1[2] - bbox1[0]) / 2 + bbox1[0], (bbox1[3] - bbox1[1]) / 2 + bbox1[1])\n",
    "        center2 = (bbox2[0] + bbox2[2] / 2, bbox2[1] + bbox2[3] / 2)\n",
    "        return np.linalg.norm(np.array(center1) - np.array(center2))\n",
    "    \n",
    "    def process_sequence(self, seq_num):\n",
    "        input_directory = os.path.join(self.base_input_directory, f\"seq{seq_num}/img/\")\n",
    "        output_filename = os.path.join(self.output_directory, f\"trackresults_improved_seq{seq_num}.txt\")\n",
    "\n",
    "        firsttrack = self.load_firsttrack(seq_num)\n",
    "        \n",
    "        with open(output_filename, 'w') as output_file:\n",
    "            image_files = sorted([f for f in os.listdir(input_directory) if f.endswith(\".jpg\")])\n",
    "            prev_bbox = None\n",
    "            \n",
    "            for idx, image_file in enumerate(image_files):\n",
    "                image_path = os.path.join(input_directory, image_file)\n",
    "                image = cv2.imread(image_path)\n",
    "                results = self.yolo_model.predict(image)\n",
    "\n",
    "                boxes = results.xyxy[0].cpu().numpy()\n",
    "                detections = [[box[:4], box[4]] for box in boxes]\n",
    "                detections = np.array(detections) if len(detections) > 0 else []\n",
    "                \n",
    "                if len(detections) > 0:\n",
    "                    # Select the bbox closest to the previous one or groundtruth\n",
    "                    best_bbox = None\n",
    "                    min_dist = float('inf')\n",
    "                    reference_bbox = prev_bbox if prev_bbox is not None else firsttrack[0]\n",
    "                    \n",
    "                    for det in detections:\n",
    "                        bbox = det[0]\n",
    "                        dist = self.calculate_distance(bbox, reference_bbox)\n",
    "                        if dist < min_dist:\n",
    "                            min_dist = dist\n",
    "                            best_bbox = bbox\n",
    "\n",
    "                    if min_dist > 50:\n",
    "                        best_bbox = None\n",
    "                    \n",
    "                    if best_bbox is not None:\n",
    "                        prev_bbox = [best_bbox[0], best_bbox[1], best_bbox[2] - best_bbox[0], best_bbox[3] - best_bbox[1]]\n",
    "                \n",
    "                if prev_bbox is None:\n",
    "                    prev_bbox = firsttrack[0]\n",
    "                \n",
    "                # x_min, y_min, x_max, y_max = prev_bbox\n",
    "                output_file.write(f\"{int(prev_bbox[0])},{int(prev_bbox[1])},{int(prev_bbox[2])},{int(prev_bbox[3])}\\n\")\n",
    "        \n",
    "        print(f\"Processing of seq{seq_num} is complete. Results saved to {output_filename}\")\n",
    "\n",
    "    def load_groundtruth(self, groundtruth_filename):\n",
    "        with open(groundtruth_filename, 'r') as f:\n",
    "            groundtruth = [list(map(int, line.strip().split(','))) for line in f.readlines()]\n",
    "        return groundtruth\n",
    "\n",
    "    def run(self):\n",
    "        for seq_num in self.seq_list:\n",
    "            self.process_sequence(seq_num)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_input_directory = \"data/\"\n",
    "    deepsort_model_path = \"deep_sort/deep/checkpoint/ckpt.t7\"\n",
    "    yolo_model_path = \"yolov5s.pt\"\n",
    "    output_directory = \"results/3_improved/\"\n",
    "    seq_list = [1, 2, 3, 4, 5]\n",
    "    firsttrack_filename = \"firsttrack.txt\"\n",
    "    \n",
    "    tracker = ObjectTracking(yolo_model_path, deepsort_model_path, base_input_directory, output_directory, seq_list, firsttrack_filename)\n",
    "    tracker.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2 Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the Single object tracking algorithm for both **Template Matching** and **Detection Algorithm with Association**. Using the **Success** and **Precision** metrics. \n",
    "\n",
    "$$\n",
    "Success = \\frac{BB_{tr} \\cap BB_{gt}}{BB_{tr} \\cup BB_{gt}} ;    \n",
    "Precision = || C_{tr} - C_{gt} ||_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.2.1 Find the best template matching method\n",
    "Use this evaluation script that assesses the tracking results for all five sequences using different template matching methods to figure out which template matching method is suitable for which sequence.\n",
    "\n",
    "The precision criterion was set to 25 pixels and the IoU criterion was set to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(boxA, boxB):\n",
    "    \"\"\"Compute the Intersection over Union (IoU) of two bounding boxes.\"\"\"\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])\n",
    "    yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])\n",
    "\n",
    "    interWidth = max(0, xB - xA)\n",
    "    interHeight = max(0, yB - yA)\n",
    "    interArea = interWidth * interHeight\n",
    "\n",
    "    boxAArea = boxA[2] * boxA[3]\n",
    "    boxBArea = boxB[2] * boxB[3]\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def calculate_precision(gt_center, tr_center):\n",
    "    \"\"\"Compute the Euclidean distance between ground truth and tracker center.\"\"\"\n",
    "    return np.linalg.norm(np.array(gt_center) - np.array(tr_center))\n",
    "\n",
    "\n",
    "def read_bounding_boxes(file_path):\n",
    "    \"\"\"Read bounding boxes from a file.\"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        boxes = [list(map(int, line.strip().split(\",\"))) for line in lines]\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def evaluate_tracking(gt_file, tr_file, precision_threshold=20, iou_threshold=0.5):\n",
    "    \"\"\"Evaluate tracking results using precision and success metrics.\"\"\"\n",
    "    gt_boxes = read_bounding_boxes(gt_file)\n",
    "    tr_boxes = read_bounding_boxes(tr_file)\n",
    "\n",
    "    assert len(gt_boxes) == len(\n",
    "        tr_boxes\n",
    "    ), \"Ground truth and tracking files must have the same number of frames.\"\n",
    "\n",
    "    total_frames = len(gt_boxes)\n",
    "    precision_count = 0\n",
    "    success_count = 0\n",
    "    iou_list = []\n",
    "    precision_list = []\n",
    "\n",
    "    for gt_box, tr_box in zip(gt_boxes, tr_boxes):\n",
    "        gt_center = (gt_box[0] + gt_box[2] // 2, gt_box[1] + gt_box[3] // 2)\n",
    "        tr_center = (tr_box[0] + tr_box[2] // 2, tr_box[1] + tr_box[3] // 2)\n",
    "\n",
    "        # Compute Precision\n",
    "        distance = calculate_precision(gt_center, tr_center)\n",
    "        precision_list.append(distance)\n",
    "        if distance <= precision_threshold:\n",
    "            precision_count += 1\n",
    "\n",
    "        # Compute IoU Success\n",
    "        iou = calculate_iou(gt_box, tr_box)\n",
    "        iou_list.append(iou)\n",
    "        if iou >= iou_threshold:\n",
    "            success_count += 1\n",
    "\n",
    "    precision = precision_count / total_frames\n",
    "    success = success_count / total_frames\n",
    "\n",
    "    return precision, success, iou_list, precision_list\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_gt_directory = \"data/\"\n",
    "    gt_filename = \"groundtruth.txt\"\n",
    "    tracking_result_directory = \"results/1_template_matching/\"\n",
    "\n",
    "    precision_threshold = 25  # Pixels\n",
    "    iou_threshold = 0.5  # IoU threshold\n",
    "    seq_list = [1, 2, 3, 4, 5]\n",
    "    methods = [\n",
    "        \"TM_CCOEFF\",\n",
    "        \"TM_CCOEFF_NORMED\",\n",
    "        \"TM_CCORR\",\n",
    "        \"TM_CCORR_NORMED\",\n",
    "        \"TM_SQDIFF\",\n",
    "        \"TM_SQDIFF_NORMED\",\n",
    "    ]\n",
    "\n",
    "    iou_results = pd.DataFrame(columns=methods, index=seq_list)\n",
    "    precision_results = pd.DataFrame(columns=methods, index=seq_list)\n",
    "\n",
    "    for seq_num in seq_list:\n",
    "        ground_truth_file = os.path.join(\n",
    "            base_gt_directory, f\"seq{seq_num}/\", gt_filename\n",
    "        )\n",
    "        for method in methods:\n",
    "            tracking_result_file = os.path.join(\n",
    "                tracking_result_directory, f\"seq{seq_num}/trackresults_{method}.txt\"\n",
    "            )\n",
    "\n",
    "            if os.path.exists(tracking_result_file):\n",
    "                precision, success, _, _ = evaluate_tracking(\n",
    "                    ground_truth_file,\n",
    "                    tracking_result_file,\n",
    "                    precision_threshold,\n",
    "                    iou_threshold,\n",
    "                )\n",
    "                iou_results.loc[seq_num, method] = success * 100\n",
    "                precision_results.loc[seq_num, method] = precision * 100\n",
    "            else:\n",
    "                iou_results.loc[seq_num, method] = None\n",
    "                precision_results.loc[seq_num, method] = None\n",
    "\n",
    "    iou_results.to_csv(f\"iou_results_with_threshold{iou_threshold}.csv\")\n",
    "    precision_results.to_csv(\n",
    "        f\"precision_results_with_threshold{precision_threshold}.csv\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Results saved to 'iou_results_with_threshold{iou_threshold}.csv' and 'precision_results_with_threshold{precision_threshold}.csv'\"\n",
    "    )\n",
    "\n",
    "    print(\"IoU Results:\")\n",
    "    print(iou_results.to_markdown())\n",
    "\n",
    "    print(\"\\nPrecision Results:\")\n",
    "    print(precision_results.to_markdown())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.2.2 Evaluation of Template Matching with Adaptive Template Update and Kalman Filtering\n",
    "\n",
    "This script evaluates and compares three object tracking methods— TM, TM + ATU, and TM + ATU + KF —by measuring precision and IoU success rates across different sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plot_results(\n",
    "    iou_list,\n",
    "    precision_list,\n",
    "    only_tm_iou_list,\n",
    "    only_tm_precision_list,\n",
    "    kf_iou_list,\n",
    "    kf_precision_list,\n",
    "    precision_threshold,\n",
    "    iou_threshold,\n",
    "    seq_num,\n",
    "    tracking_result_directory\n",
    "):\n",
    "    \"\"\"Plot IoU and Precision per frame with threshold lines.\"\"\"\n",
    "    frames = range(len(iou_list))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot IoU\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(frames, only_tm_iou_list, label=\"TM\", color=\"green\")\n",
    "    plt.plot(frames, iou_list, label=\"TM + ATU\", color=\"blue\")\n",
    "    plt.plot(frames, kf_iou_list, label=\"TM + ATU + KF\", color=\"orange\")\n",
    "    plt.axhline(\n",
    "        y=iou_threshold,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"IoU Threshold = {iou_threshold}\",\n",
    "    )\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.ylabel(\"IoU\")\n",
    "    plt.title(f\"IoU per frame for Sequence {seq_num}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    # Plot Precision\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(frames, only_tm_precision_list, label=\"TM\", color=\"green\")\n",
    "    plt.plot(frames, precision_list, label=\"TM + ATU\", color=\"blue\")\n",
    "    plt.plot(frames, kf_precision_list, label=\"TM + ATU + KF\", color=\"orange\")\n",
    "    plt.axhline(\n",
    "        y=precision_threshold,\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Precision Threshold = {precision_threshold}\",\n",
    "    )\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.ylabel(\"Euclidean Distance\")\n",
    "    plt.title(f\"Precision per frame for Sequence {seq_num}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{tracking_result_directory}/Precision per frame for Sequence {seq_num}\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_gt_directory = \"data/\"\n",
    "    gt_filename = \"groundtruth.txt\"\n",
    "    tracking_result_directory = \"results/1_template_matching/\"\n",
    "\n",
    "    precision_threshold = 25  # Pixels\n",
    "    iou_threshold = 0.5  # IoU threshold\n",
    "    seq_list = [1, 2, 3, 4, 5]\n",
    "    seq_matching_methods = {\n",
    "        1: \"TM_CCOEFF\",\n",
    "        2: \"TM_CCOEFF\",\n",
    "        3: \"TM_CCOEFF_NORMED\",\n",
    "        4: \"TM_SQDIFF_NORMED\",\n",
    "        5: \"TM_CCOEFF_NORMED\",\n",
    "    }\n",
    "\n",
    "    for seq_num in seq_list:\n",
    "        ground_truth_file = (\n",
    "            os.path.join(base_gt_directory, f\"seq{seq_num}/\") + gt_filename\n",
    "        )\n",
    "\n",
    "        # Only TM\n",
    "        matching_method = seq_matching_methods[seq_num]\n",
    "        only_tm_result_file = os.path.join(\n",
    "            tracking_result_directory,\n",
    "            f\"seq{seq_num}/trackresults_{matching_method}.txt\",\n",
    "        )\n",
    "        only_tm_precision, only_tm_success, only_tm_iou_list, only_tm_precision_list = (\n",
    "            evaluate_tracking(\n",
    "                ground_truth_file,\n",
    "                only_tm_result_file,\n",
    "                precision_threshold,\n",
    "                iou_threshold,\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            f\"TM Success (IoU threshold = {iou_threshold}):                  {only_tm_success * 100:.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"TM Precision (threshold = {precision_threshold} pixels):              {only_tm_precision * 100:.2f}%\"\n",
    "        )\n",
    "\n",
    "        # TM + ATU\n",
    "        tracking_result_file = os.path.join(\n",
    "            tracking_result_directory, f\"trackresults_TM_ATU_seq{seq_num}.txt\"\n",
    "        )\n",
    "        precision, success, iou_list, precision_list = evaluate_tracking(\n",
    "            ground_truth_file, tracking_result_file, precision_threshold, iou_threshold\n",
    "        )\n",
    "        print(\n",
    "            f\"TM + ATU Success (IoU threshold = {iou_threshold}):            {success * 100:.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"TM + ATU Precision (threshold = {precision_threshold} pixels):        {precision * 100:.2f}%\"\n",
    "        )\n",
    "\n",
    "        # TM + KF\n",
    "        kf_tracking_result_file = os.path.join(\n",
    "            tracking_result_directory, f\"trackresults_TM_ATU_KF_seq{seq_num}.txt\"\n",
    "        )\n",
    "        kf_precision, kf_success, kf_iou_list, kf_precision_list = evaluate_tracking(\n",
    "            ground_truth_file,\n",
    "            kf_tracking_result_file,\n",
    "            precision_threshold,\n",
    "            iou_threshold,\n",
    "        )\n",
    "        print(\n",
    "            f\"TM + ATU + KF Success (IoU threshold = {iou_threshold}):       {kf_success * 100:.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"TM + ATU + KF Precision (threshold = {precision_threshold} pixels):   {kf_precision * 100:.2f}%\"\n",
    "        )\n",
    "\n",
    "        avg_kf_success = sum(kf_iou_list) / len(kf_iou_list)\n",
    "        print(f\"TM + ATU + KF Average Success:   {avg_kf_success * 100:.2f}%\")\n",
    "        avg_kf_precision = sum(kf_precision_list) / len(kf_precision_list)\n",
    "        print(f\"TM + ATU + KF Average Precision: {avg_kf_precision * 100:.2f} pixels\")\n",
    "\n",
    "        plot_results(\n",
    "            iou_list,\n",
    "            precision_list,\n",
    "            only_tm_iou_list,\n",
    "            only_tm_precision_list,\n",
    "            kf_iou_list,\n",
    "            kf_precision_list,\n",
    "            precision_threshold,\n",
    "            iou_threshold,\n",
    "            seq_num,\n",
    "            tracking_result_directory\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.2.3 Evaluation of Object Detection Algorithm with Association\n",
    "This script evaluates ODA by measuring precision and IoU success rates across different sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plot_results(\n",
    "    iou_list,\n",
    "    precision_list,\n",
    "    precision_threshold,\n",
    "    iou_threshold,\n",
    "    seq_num,\n",
    "    tracking_result_directory,\n",
    "):\n",
    "    \"\"\"Plot IoU and Precision per frame with threshold lines.\"\"\"\n",
    "    frames = range(len(iou_list))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot IoU\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(frames, iou_list, label=\"ODA\", color=\"blue\")\n",
    "    plt.axhline(\n",
    "        y=iou_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"IoU Threshold = {iou_threshold}\",\n",
    "    )\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.ylabel(\"IoU\")\n",
    "    plt.title(f\"IoU per frame for Sequence {seq_num}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    # Plot Precision\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(frames, precision_list, label=\"ODA\", color=\"green\")\n",
    "    plt.axhline(\n",
    "        y=precision_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Precision Threshold = {precision_threshold}\",\n",
    "    )\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.ylabel(\"Euclidean Distance\")\n",
    "    plt.title(f\"Precision per frame for Sequence {seq_num}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{tracking_result_directory}/Precision per frame for Sequence {seq_num}\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_gt_directory = \"data/\"\n",
    "    gt_filename = \"groundtruth.txt\"\n",
    "    tracking_result_directory = \"results/2_objectdetection_withassociation/\"\n",
    "\n",
    "    precision_threshold = 25  # Pixels\n",
    "    iou_threshold = 0.5  # IoU threshold\n",
    "    seq_list = [1,2,3,4,5]\n",
    "\n",
    "    for seq_num in seq_list:\n",
    "        ground_truth_file = (\n",
    "            os.path.join(base_gt_directory, f\"seq{seq_num}/\") + gt_filename\n",
    "        )\n",
    "\n",
    "        # ODA\n",
    "        tracking_result_file = os.path.join(\n",
    "            tracking_result_directory, f\"trackresults_ODA_seq{seq_num}.txt\"\n",
    "        )\n",
    "        precision, success, iou_list, precision_list = evaluate_tracking(\n",
    "            ground_truth_file, tracking_result_file, precision_threshold, iou_threshold\n",
    "        )\n",
    "        print(\n",
    "            f\"ODA Success (IoU threshold = {iou_threshold}):            {success * 100:.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"ODA Precision (threshold = {precision_threshold} pixels):        {precision * 100:.2f}%\"\n",
    "        )\n",
    "\n",
    "        avg_oda_success = sum(iou_list) / len(iou_list)\n",
    "        print(f\"ODA Average Success:   {avg_oda_success * 100:.2f}%\")\n",
    "        avg_oda_precision = sum(precision_list) / len(precision_list)\n",
    "        print(f\"ODA Average Precision: {avg_oda_precision * 100:.2f} pixels\")\n",
    "\n",
    "        plot_results(\n",
    "            iou_list,\n",
    "            precision_list,\n",
    "            precision_threshold,\n",
    "            iou_threshold,\n",
    "            seq_num,\n",
    "            tracking_result_directory\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1.2.4 Evaluation of YOLO and Deep SORT\n",
    "This script evaluates YOLO and Deep SORT by measuring precision and IoU success rates across different sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plot_results(\n",
    "    iou_list,\n",
    "    precision_list,\n",
    "    precision_threshold,\n",
    "    iou_threshold,\n",
    "    seq_num,\n",
    "    tracking_result_directory,\n",
    "):\n",
    "    \"\"\"Plot IoU and Precision per frame with threshold lines.\"\"\"\n",
    "    frames = range(len(iou_list))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot IoU\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(frames, iou_list, label=\"YOLO + Deep SORT\", color=\"blue\")\n",
    "    plt.axhline(\n",
    "        y=iou_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"IoU Threshold = {iou_threshold}\",\n",
    "    )\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.ylabel(\"IoU\")\n",
    "    plt.title(f\"IoU per frame for Sequence {seq_num}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    # Plot Precision\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(frames, precision_list, label=\"YOLO + Deep SORT\", color=\"green\")\n",
    "    plt.axhline(\n",
    "        y=precision_threshold,\n",
    "        color=\"r\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Precision Threshold = {precision_threshold}\",\n",
    "    )\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.ylabel(\"Euclidean Distance\")\n",
    "    plt.title(f\"Precision per frame for Sequence {seq_num}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{tracking_result_directory}/Precision per frame for Sequence {seq_num}\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_gt_directory = \"data/\"\n",
    "    gt_filename = \"groundtruth.txt\"\n",
    "    tracking_result_directory = \"results/3_improved/\"\n",
    "\n",
    "    precision_threshold = 25  # Pixels\n",
    "    iou_threshold = 0.5  # IoU threshold\n",
    "    seq_list = [1,2,3,4,5]\n",
    "    only_tm_iou_list, only_tm_precision_list, kf_iou_list, kf_precision_list = [], [], [], []\n",
    "\n",
    "    for seq_num in seq_list:\n",
    "        ground_truth_file = (\n",
    "            os.path.join(base_gt_directory, f\"seq{seq_num}/\") + gt_filename\n",
    "        )\n",
    "\n",
    "        # YOLO\n",
    "        tracking_result_file = os.path.join(\n",
    "            tracking_result_directory, f\"trackresults_improved_seq{seq_num}.txt\"\n",
    "        )\n",
    "        precision, success, iou_list, precision_list = evaluate_tracking(\n",
    "            ground_truth_file, tracking_result_file, precision_threshold, iou_threshold\n",
    "        )\n",
    "        print(\n",
    "            f\"YOLO + Deep SORT Success (IoU threshold = {iou_threshold}):            {success * 100:.2f}%\"\n",
    "        )\n",
    "        print(\n",
    "            f\"YOLO + Deep SORT Precision (threshold = {precision_threshold} pixels):        {precision * 100:.2f}%\"\n",
    "        )\n",
    "\n",
    "        avg_yolo_success = sum(iou_list) / len(iou_list)\n",
    "        print(f\"YOLO + Deep SORT Average Success:   {avg_yolo_success * 100:.2f}%\")\n",
    "        avg_yolo_precision = sum(precision_list) / len(precision_list)\n",
    "        print(f\"YOLO + Deep SORT Average Precision: {avg_yolo_precision * 100:.2f} pixels\")\n",
    "\n",
    "        plot_results(\n",
    "            iou_list,\n",
    "            precision_list,\n",
    "            precision_threshold,\n",
    "            iou_threshold,\n",
    "            seq_num,\n",
    "            tracking_result_directory,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3 Visualization\n",
    "Visualise the results as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## put your code here: This function should be able to visualise this image and their tracking results\n",
    "img_file = 'data/Task 1/seq2/img/00000002.jpg'\n",
    "\n",
    "print('Tracking Results for this image using Template matching is (in xmin, ymin, width, height): ???')\n",
    "## show image of visualised result of ground truth and track results\n",
    "\n",
    "print('Tracking Results for this image using Object Detection is(in xmin, ymin, width, height): ???')\n",
    "## show image of visualised result of ground truth and track results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the GT (blue), TM (green), and ODA (red) bbox results for the second frame in all scenes.\n",
    "__Please press any key to view the next sample image.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base directories for input and output\n",
    "base_input_directory = 'data/'  # Path to the image directory\n",
    "base_result_directory = 'results/1_template_matching'  # Path to the result directory for template matching\n",
    "object_detection_result_directory = 'results/2_objectdetection_withassociation'  # Path to the result directory for object detection\n",
    "groundtruth_directory = 'data/'  # Path to the ground truth directory\n",
    "\n",
    "# List of sequence numbers\n",
    "seq_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Loop through each sequence\n",
    "for seq_num in seq_list:\n",
    "    # Define file paths based on the sequence number\n",
    "    img_file = os.path.join(base_input_directory, f\"seq{seq_num}/img/00000002.jpg\")\n",
    "    print(img_file)\n",
    "    template_matching_result_file = os.path.join(base_result_directory, f\"trackresults_TM_ATU_KF_seq{seq_num}.txt\")\n",
    "    object_detection_result_file = os.path.join(object_detection_result_directory, f\"trackresults_ODA_seq{seq_num}.txt\")\n",
    "    groundtruth_file = os.path.join(groundtruth_directory, f\"seq{seq_num}/groundtruth.txt\")\n",
    "\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_file)\n",
    "\n",
    "    # Function to read the second line (index 1) from a file and parse it\n",
    "    def read_bounding_box(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            # The bounding box is in the format [x, y, width, height]\n",
    "            bbox = eval(lines[1].strip())  # Safely convert string '[x, y, width, height]' to a list\n",
    "        return bbox\n",
    "\n",
    "    # Read the tracking results from Template Matching and Object Detection\n",
    "    template_matching_bbox = read_bounding_box(template_matching_result_file)\n",
    "    object_detection_bbox = read_bounding_box(object_detection_result_file)\n",
    "\n",
    "    # Read the ground truth bounding box\n",
    "    groundtruth_bbox = read_bounding_box(groundtruth_file)\n",
    "\n",
    "    # Draw the bounding boxes\n",
    "    # Ground truth in red (BGR color: [0, 0, 255])\n",
    "    cv2.rectangle(img, (groundtruth_bbox[0], groundtruth_bbox[1]), \n",
    "                  (groundtruth_bbox[0] + groundtruth_bbox[2], groundtruth_bbox[1] + groundtruth_bbox[3]), \n",
    "                  (0, 0, 255), 1)\n",
    "    # Label the Ground Truth\n",
    "    cv2.putText(img, \"GT\", (groundtruth_bbox[0], groundtruth_bbox[1] - 10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    # Template Matching result in green (BGR color: [0, 255, 0])\n",
    "    cv2.rectangle(img, (template_matching_bbox[0], template_matching_bbox[1]), \n",
    "                  (template_matching_bbox[0] + template_matching_bbox[2], template_matching_bbox[1] + template_matching_bbox[3]), \n",
    "                  (0, 255, 0), 1)\n",
    "    # Label the Template Matching\n",
    "    cv2.putText(img, \"   TM\", (template_matching_bbox[0], template_matching_bbox[1] - 10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # Object Detection result in blue (BGR color: [255, 0, 0])\n",
    "    cv2.rectangle(img, (object_detection_bbox[0], object_detection_bbox[1]), \n",
    "                  (object_detection_bbox[0] + object_detection_bbox[2], object_detection_bbox[1] + object_detection_bbox[3]), \n",
    "                  (255, 0, 0), 1)\n",
    "    # Label the Object Detection\n",
    "    cv2.putText(img, \"      ODA\", (object_detection_bbox[0], object_detection_bbox[1] - 10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "    # Display the image in a new window\n",
    "    cv2.imshow(f\"Tracking Results - Seq{seq_num}\", img)\n",
    "\n",
    "    # Wait until a key is pressed, then close the window\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Print out the results\n",
    "    print(f\"Tracking Results for sequence {seq_num}:\")\n",
    "    print(f\"Template matching: {template_matching_bbox}\")\n",
    "    print(f\"Object Detection: {object_detection_bbox}\")\n",
    "    print(f\"Ground truth: {groundtruth_bbox}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate comparison videos of the perceived GT bboxes and the used detection tracking scheme for all sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox_on_image(image, bbox, r, g, b, label, thickness=1):\n",
    "    \"\"\"Draw a bounding box on the image and draw a red dot at the center\"\"\"\n",
    "    x, y, w, h = map(int, bbox)\n",
    "    center_x, center_y = x + w // 2, y + h // 2\n",
    "    \n",
    "    # Draw bbox\n",
    "    color = (r, g, b)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), color, thickness)\n",
    "\n",
    "    # Label the Template Matching\n",
    "    cv2.putText(image, label, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)\n",
    "    \n",
    "    # Draw the center point\n",
    "    cv2.circle(image, (center_x, center_y), radius=4, color=(r, g, b), thickness=-1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def process_images(seq_num, base_input_directory, base_output_directory):\n",
    "    img_dir = os.path.join(base_input_directory, f\"seq{seq_num}\", \"img\")\n",
    "    gt_file = os.path.join(base_input_directory, f\"seq{seq_num}\", \"groundtruth.txt\")\n",
    "    tm_file = os.path.join(f\"results/1_template_matching\", f\"trackresults_TM_ATU_KF_seq{seq_num}.txt\")\n",
    "    oda_file = os.path.join(f\"results/2_objectdetection_withassociation\", f\"trackresults_ODA_seq{seq_num}.txt\")\n",
    "    imp_file = os.path.join(f\"results/3_improved\", f\"trackresults_improved_seq{seq_num}.txt\")\n",
    "    \n",
    "    output_video_tm = os.path.join(base_output_directory, f\"1_template_matching\", f\"comparison_video_TM_seq{seq_num}.avi\")\n",
    "    output_video_oda = os.path.join(base_output_directory, f\"2_objectdetection_withassociation\", f\"comparison_video_ODA_seq{seq_num}.avi\")\n",
    "    output_video_imp = os.path.join(base_output_directory, f\"3_improved\", f\"comparison_video_improved_seq{seq_num}.avi\")\n",
    "    \n",
    "    # Read groundtruth.txt\n",
    "    with open(gt_file, 'r') as f:\n",
    "        gt_bboxes = [line.strip().split(',') for line in f.readlines()]\n",
    "\n",
    "    # Read trackresults_TM_ATU_KF_seq.txt\n",
    "    with open(tm_file, 'r') as f:\n",
    "        tm_bboxes = [line.strip().split(',') for line in f.readlines()]\n",
    "    \n",
    "    # Read trackresults_ODA_seqX.txt\n",
    "    with open(oda_file, 'r') as f:\n",
    "        oda_bboxes = [line.strip().split(',') for line in f.readlines()]\n",
    "\n",
    "    # Read trackresults_improved_seqX.txt\n",
    "    with open(imp_file, 'r') as f:\n",
    "        imp_bboxes = [line.strip().split(',') for line in f.readlines()]\n",
    "    \n",
    "    # Get all image files\n",
    "    img_files = sorted([f for f in os.listdir(img_dir) if f.endswith('.jpg')])\n",
    "    \n",
    "    if len(img_files) != len(gt_bboxes):\n",
    "        raise ValueError(\"The number of images does not match the number of lines in groundtruth.txt\")\n",
    "    if len(img_files) != len(tm_bboxes):\n",
    "        raise ValueError(f\"The number of images does not match the number of lines in trackresults_TM_ATU_KF_seq{seq_num}.txt\")\n",
    "    if len(img_files) != len(oda_bboxes):\n",
    "        raise ValueError(f\"The number of images does not match the number of lines in trackresults_ODA_seq{seq_num}.txt\")\n",
    "    if len(img_files) != len(imp_bboxes):\n",
    "        raise ValueError(f\"The number of images does not match the number of lines in trackresults_improved_seq{seq_num}.txt\")\n",
    "    \n",
    "    # Read the first image to get the size\n",
    "    first_img = cv2.imread(os.path.join(img_dir, img_files[0]))\n",
    "    height, width, _ = first_img.shape\n",
    "    \n",
    "    # Initialize video writers\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'FFV1')  # Use FFV1 encoding (no compression)\n",
    "    \n",
    "    video_writer_tm = cv2.VideoWriter(output_video_tm, fourcc, 30, (width, height))\n",
    "    video_writer_oda = cv2.VideoWriter(output_video_oda, fourcc, 30, (width, height))\n",
    "    video_writer_imp = cv2.VideoWriter(output_video_imp, fourcc, 30, (width, height))\n",
    "    \n",
    "    for img_file, gt_bbox, tm_bbox, oda_bbox, imp_bbox in zip(img_files, gt_bboxes, tm_bboxes, oda_bboxes, imp_bboxes):\n",
    "        img_path = os.path.join(img_dir, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        if img is None:\n",
    "            print(f\"Warning: Unable to read {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Draw bounding boxes and labels for Template Matching (TM)\n",
    "        img_tm = img.copy()\n",
    "        img_tm = draw_bbox_on_image(img_tm, gt_bbox, 0, 255, 255, \"GT\")\n",
    "        img_tm = draw_bbox_on_image(img_tm, tm_bbox, 255, 255, 0, \"TM\")\n",
    "        \n",
    "        # Draw bounding boxes and labels for Object Detection (ODA)\n",
    "        img_oda = img.copy()\n",
    "        img_oda = draw_bbox_on_image(img_oda, gt_bbox, 0, 255, 255, \"GT\")\n",
    "        img_oda = draw_bbox_on_image(img_oda, oda_bbox, 255, 0, 0, \"ODA\")\n",
    "\n",
    "        # Draw bounding boxes and labels for Object Detection (YOLO)\n",
    "        img_imp = img.copy()\n",
    "        img_imp = draw_bbox_on_image(img_imp, gt_bbox, 0, 255, 255, \"GT\")\n",
    "        img_imp = draw_bbox_on_image(img_imp, imp_bbox, 255, 0, 0, \"YOLO\")\n",
    "        \n",
    "        # Write the images to their respective video files\n",
    "        video_writer_tm.write(img_tm)\n",
    "        video_writer_oda.write(img_oda)\n",
    "        video_writer_imp.write(img_imp)\n",
    "    \n",
    "    # Release the video writers\n",
    "    video_writer_tm.release()\n",
    "    video_writer_oda.release()\n",
    "    video_writer_imp.release()\n",
    "    \n",
    "    print(f\"Videos for seq{seq_num} have been saved:\")\n",
    "    print(f\"  Template Matching Video: {output_video_tm}\")\n",
    "    print(f\"  Object Detection Video: {output_video_oda}\")\n",
    "    print(f\"  Object Detection Video: {output_video_imp}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_input_directory = \"data\"\n",
    "    base_output_directory = \"results\"\n",
    "    \n",
    "    seq_list = [1, 2, 3, 4, 5]\n",
    "    \n",
    "    for seq_num in seq_list:\n",
    "        process_images(seq_num, base_input_directory, base_output_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
